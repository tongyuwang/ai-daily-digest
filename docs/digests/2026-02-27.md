# AI Digest â€” February 27, 2026

> Curated from Tony's X/Twitter bookmarks. [â† Back to index](index.md)

---

## ğŸ§  Key Themes

- **The Inflection Point Is Now** â€” Karpathy puts a timestamp on it: coding agents "basically didn't work before December" and "basically work since." The shift isn't gradual â€” it's a cliff. Weekend projects became 30-minute tasks, and the bottleneck has moved from code to orchestration.
- **The App Store Is Dead (or Dying)** â€” Multiple threads converging on the same idea: LLMs don't just write code, they *are* the app. Bespoke software spawned on demand, ephemeral and personal, is replacing the long tail of discrete apps.
- **AI Safety's New Frontier: AIs Hacking AIs** â€” Researchers showed reasoning models can autonomously jailbreak other AI models with a 97% success rate. No humans needed. The weapon is reasoning itself.
- **Agent Scaffolding > Model Quality** â€” Both OpenAI and Anthropic dropped harness engineering guides the same week. The community is loudly agreeing: the model isn't the bottleneck, your scaffolding is. Memory, orchestration, and context management are the new moat.
- **The Obsidian + Claude Code Moment** â€” A new stack pattern is crystallizing: write everything in markdown, link it like your brain, let Claude agents read and act on it. Multiple high-engagement posts converging on this as the "personal OS" paradigm.

---

## ğŸ† Top Picks

### 1. Karpathy: Coding Agents Crossed a Threshold in December
**[@karpathy](https://x.com/karpathy/status/2026731645169185220)** Â· ğŸ‘ 4.4M impressions Â· ğŸ”– 19,167 bookmarks

The most-bookmarked AI post this cycle. Karpathy writes that coding agents "basically didn't work before December and basically work since" â€” driven by higher quality, long-term coherence, and tenacity that lets them power through large, long tasks. His proof: he gave an agent his DGX Spark IP/credentials and told it to set up vLLM, download Qwen3-VL, build a web dashboard, test everything, set up systemd, and write a report. The agent went off for ~30 minutes, hit multiple issues, researched solutions online, resolved them, and came back with everything done. "I didn't touch anything." His frame for what comes next: ascending layers of abstraction to set up long-running orchestrator Claws managing multiple parallel Code instances. The leverage of "top tier agentic engineering" feels very high right now.

---

### 2. Claude Cowork Setup Guide (55k Bookmarks)
**[Article via @](https://x.com/i/article/2026703184945885189)** Â· ğŸ‘ 5.3M impressions Â· ğŸ”– 55,786 bookmarks

*"How to set up Claude Cowork the right way (so it actually does your work while you step away)"* â€” the single most-bookmarked item in Tony's list by a wide margin. The piece walks through the full setup: AGENTS.md architecture, memory systems, email pipelines, cron jobs, multi-prompt versions, Telegram groups, CRM, meeting intelligence, OAuth security, and cost tracking. The subtitle says it all: this is the guide people want for turning Claude into an autonomous work system.

---

### 3. OpenClaw + Codex/ClaudeCode Agent Swarm: The One-Person Dev Team
**[Article](https://x.com/i/article/2025654698590748672)** Â· ğŸ‘ 4.6M impressions Â· ğŸ”– 34,355 bookmarks

Full setup guide for running OpenClaw as the orchestrator with Claude Code/Codex as worker agents. Frames the pattern as "the one-person dev team" â€” one human setting direction, one orchestrator managing priorities, multiple code agents executing in parallel. The article reportedly walks through the full architecture end to end.

---

### 4. Sakana AI: Doc-to-LoRA and Text-to-LoRA
**[@SakanaAILabs](https://x.com/SakanaAILabs/status/2027240298666209535)** Â· ğŸ‘ 151K impressions Â· ğŸ”– 862 bookmarks Â· [Research](https://pub.sakana.ai/doc-to-lora/)

Fresh from this morning (4:32 AM). Sakana introduces hypernetworks that generate LoRA adapters on the fly â€” sub-second latency, no retraining required. **Doc-to-LoRA** compresses documents into LoRA weights so a model can recall factual content beyond its context window (near-perfect on needle-in-a-haystack at 5Ã— the base context). **Text-to-LoRA** creates task-specific adapters from natural language descriptions alone. The authors frame it as the missing piece for continual LLM adaptation â€” pay the meta-training cost once, then customization becomes a single forward pass.

---

### 5. AI Models Can Now Autonomously Jailbreak Other AI Models
**[@heynavtoor](https://x.com/heynavtoor/status/2027037778287153213)** Â· ğŸ‘ 94K impressions Â· ğŸ”– 944 bookmarks

The paper is "Large Reasoning Models Are Autonomous Jailbreak Agents." Researchers from Stuttgart and ELLIS Alicante gave four reasoning models (DeepSeek-R1, Gemini 2.5 Flash, Grok 3 Mini, Qwen3 235B) one instruction: "Jailbreak this AI." Then walked away. The models planned their own attack strategy, chose manipulation tactics, ran multi-turn conversations with targets, adapted in real time â€” and broke through with a **97.14% success rate** across nine widely-deployed models. The insight: "alignment regression" â€” the smarter a model gets at chain-of-thought reasoning, the better it becomes at persuading other AIs to abandon safety training. Cost to replicate: ~$0.02 per attack.

---

## ğŸ“Œ Also Bookmarked

**Karpathy: The App Store Is Dead** â€” [@karpathy](https://x.com/karpathy/status/2024583544157458452) (ğŸ”– 7,933) â€” His cardio experiment thread isn't really about fitness. It's a manifesto: there should never be a "Cardio experiment tracker" app on the App Store. An LLM agent should spin one up in seconds. The industry needs to reconfigure into AI-native sensors and actuators. "What has to be in place so that it would be 1 minute?" He's disappointed with how slowly products are adopting agent-native CLIs. "99% of products still don't have an AI-native CLI yet. In 2026."

**Perplexity Computer: 19-Model Orchestrator** â€” [@PawelHuryn](https://x.com/PawelHuryn/status/2026808127371317510) (ğŸ”– 2,503) â€” Perplexity launched "Perplexity Computer" â€” 19 models, each subtask routed to the best one (Opus 4.6 for reasoning, Gemini for research with sub-agents, Grok for speed, Veo 3.1 for video, ChatGPT 5.2 for long-context). Runs on a schedule, connects to GitHub/Drive/Gmail/Slack/Jira/Linear/Notion. The pitch: "managed OpenClaw â€” similar autonomous capability but fully managed. No Mac Mini. No security config."

**OpenFang: An OS for AI Agents** â€” [@Akashi203](https://x.com/Akashi203/status/2026817793165779387) (ğŸ”– 5,166) â€” 137k lines of Rust, MIT licensed. Agents run in WASM sandboxes like processes on Linux â€” kernel-scheduled, resource-metered, killed if rogue. 16 security layers baked in. "Hands" are always-on agents that run 24/7 without prompting. Inspired by OpenClaw. [GitHub](http://github.com/RightNow-AI/openfang)

**Obsidian + Claude Code as 24/7 Personal OS** â€” [@gregisenberg](https://x.com/gregisenberg/status/2026036464287412412) (ğŸ”– 14,893) â€” Greg Isenberg's full breakdown: write everything in markdown, link notes like your brain, install Obsidian CLI so Claude Code can read your entire vault + relationships, stop reexplaining projects, build custom slash commands (/context, /trace, /connect, /ideas, /graduate). "Markdown files are the oxygen of LLMs." The vault makes the agent stop being generic and start thinking in your voice.

**Claude Code Best-Practice GitHub Repo** â€” [@hasantoxr](https://x.com/hasantoxr/status/2025554669775503699) (ğŸ”– 5,320) â€” `claude-code-best-practice` repo: production-ready Agents, Commands, Memory, Hooks, and Skills all in one place. Agents orchestrate multi-step tasks, Commands are reusable slash commands, Memory persists context across sessions, Hooks fire shell commands on tool call events.

**Obsidian + Claude Code: The CEO of Obsidian Has Skills for This** â€” [@Hesamation](https://x.com/Hesamation/status/2026801420872093708) (ğŸ”– 5,755) â€” kepano (Obsidian CEO) has published multiple Claude Code skills for both codebases and personal vaults. The combo is getting serious traction.

**Spec Is Becoming the Product** â€” [@Saboo_Shubham_](https://x.com/Saboo_Shubham_/status/2026856780798767531) (ğŸ”– 1,677) â€” An Anthropic engineer gave Claude a spec, pointed it at an Asana board, and left for the weekend. Claude broke it into tickets and spun up a team of agents that started picking up tasks autonomously. No one told them to.

**OpenClaw as Company OS (5B Tokens)** â€” [@MatthewBerman](https://x.com/MatthewBerman/status/2026450191759585776) (ğŸ”– 11,639) â€” Matthew Berman's deep walkthrough of his full OpenClaw setup after 5 billion tokens. Covers email management, inbox pipelines, multiple prompt versions, Telegram groups, CRM, meeting intelligence, knowledge base, content pipeline, security, cron jobs, memory, OAuth loophole fix, personal/work separation, and health pipeline.

**My Claude Code Skills Setup** â€” [Article](https://x.com/i/article/2024457065083617280) (ğŸ”– 6,350) â€” Curated breakdown of how someone structures their Skills for Claude Code. High engagement suggests it's hitting on a shared pain point.

**Autonomous Dogfooding Skill** â€” [@ctatedev](https://x.com/ctatedev/status/2026357704617267314) (ğŸ”– 6,072) â€” New skill for agent-browser: points at any URL and explores it like a user. Clicks buttons, fills forms, tests edge cases, checks console, captures repro videos, outputs structured severity report. No test scripts, no manual QA.

**OpenClaw Orchestrator Tip** â€” (ğŸ”– 1,314) â€” The AGENTS.md tip going viral: "You are the orchestrator. Subagents execute. Never build, verify, or code inline. Your job is to plan, prioritize & coordinate." From 1 slow agent doing everything to a CEO managing an army of workers.

**Mastra Code: Claude Code Rival with Infinite Memory** â€” [@tylbar](https://x.com/tylbar/status/2026399996237820282) (ğŸ”– 709) â€” Mastra Code is a new coding agent powered by Mastra's observational memory â€” no context compaction needed. Run coding sessions "forever."

**Vercel Chat SDK** â€” [@vercel](https://x.com/vercel/status/2026359198171402678) (ğŸ”– 1,529) â€” Write chatbot logic once, deploy across Slack, GitHub Teams, Discord, and more. Open-sourced TypeScript library in public beta.

**Ralph Loop Setup for Long-Running Agents** â€” [Article](https://x.com/i/article/2026009212296327168) (ğŸ”– 1,881) â€” Detailed setup for keeping AI agents running reliably over long tasks. Good companion piece to the harness engineering playbook.

**The Emerging Harness Engineering Playbook** â€” [Article](https://x.com/i/article/2026007830147559425) (ğŸ”– 2,138) â€” Framework for the scaffolding layer: context management, tool design, memory architecture, orchestration patterns. Both OpenAI and Anthropic dropped guides on this same week.

**Anthropic AI Fluency Index** â€” [@AnthropicAI](https://x.com/AnthropicAI/status/2025950279099961854) (ğŸ”– 2,118) â€” Anthropic tracked 11 behaviors across thousands of Claude.ai conversations to measure how people develop AI collaboration skills. [Full report](https://www.anthropic.com/research/AI-fluency-index)

**How Peter Steinberger Does Agentic Engineering** â€” [Article](https://x.com/i/article/2025986700158353408) (ğŸ”– 2,101) â€” Breakdown of the PSPDFKit founder's approach to AI-assisted engineering, plus commentary.

**Software 4.0** â€” (ğŸ”– 473) â€” The four eras: write code â†’ write neural nets â†’ write prompts (vibe code) â†’ write scaffolds giving AI near-unrestricted autonomy to build independently.

**NanoClaw: Lightweight OpenClaw Alternative** â€” [@qwibitai](https://x.com/qwibitai/nanoclaw) (ğŸ”– 107) â€” ~36k token core, container-isolated, WhatsApp-connected, built directly on Anthropic's Agents SDK. Contributes features as Skills rather than adding to the codebase.

**Every Piece of Software Is Already Written** â€” [Article](https://x.com/i/article/2026744690562023424) (ğŸ”– 36) â€” Philosophical piece on the implications of LLMs as universal code generators.

**What Personal Software Actually Is** â€” [Article](https://x.com/i/article/2026012393466163201) (ğŸ”– 472) â€” Meditation on the meaning of software that's made just for you.

**AI + Bad Codebase = Worse Results** â€” [@mattpocockuk](https://x.com/mattpocockuk/status/2026960849512870063) (ğŸ”– 798) â€” "Garbage in, garbage out." The 20-year-old solution: deep modules. Cognitive debt is the real enemy when using AI on complex codebases.

**Complexity Is the Real Enemy (with AI)** â€” [@Yuchenj_UW](https://x.com/Yuchenj_UW/status/2027082979890368597) (ğŸ”– 51) â€” "10,000 lines of code in a day with AI" isn't the flex. Complexity is the enemy for both humans and AI. Agentic engineering creates the illusion you can ship endlessly without managing design.

**OpenClaw in Medical Research** â€” [@NatalieShapira](https://x.com/NatalieShapira/status/2026062301057712396) (ğŸ”– 926) â€” Early experience with OpenClaw in a multidisciplinary collaboration. Clinical/research use cases going mainstream.

**Pi Coding Agent: The Only Real Claude Code Competitor** â€” [YouTube](https://youtu.be/f8cfH5XX-XU) (ğŸ”– 143) â€” Video covering Pi as a Claude Code alternative, with "high praise from Dan." (~64K impressions)

**Claude Code + Harness Engineering (OpenAI & Anthropic Guides)** â€” (ğŸ”– 8) â€” Both labs dropped guides on the same topic simultaneously. The scaffolding is the bottleneck, not the model.

---

*Generated 2026-02-27 Â· [View all digests](index.md)*
